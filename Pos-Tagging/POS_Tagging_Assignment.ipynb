{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n"
     ]
    }
   ],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "\n",
    "print(len(nltk_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95539"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'one', 'feature', ',', 'called', '*', '``', 'In', 'the', 'Dumpster']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the vocabulary\n",
    "This will be helpful to check if any particular test word belongs to the vocabulary or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12083\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "vocabulary = set(tokens)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the tags used in train data\n",
    "This will be useful in building TAGS MATRIX for calculating transitional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'.', 'PRON', 'NOUN', 'CONJ', 'VERB', 'DET', 'ADV', 'PRT', 'ADJ', 'NUM', 'X', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "# number of tags\n",
    "all_tags = [pair[1] for pair in train_tagged_words]\n",
    "tags = set([pair[1] for pair in train_tagged_words])\n",
    "print(len(tags))\n",
    "\n",
    "# Tag types\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERB - verbs (all tenses and modes)\n",
    "NOUN - nouns (common and proper)\n",
    "PRON - pronouns\n",
    "ADJ - adjectives\n",
    "ADV - adverbs\n",
    "ADP - adpositions (prepositions and postpositions)\n",
    "CONJ - conjunctions\n",
    "DET - determiners\n",
    "NUM - cardinal numbers\n",
    "PRT - particles or other function words\n",
    "X - other: foreign words, typos, abbreviations\n",
    ". - punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ADP': 9385,\n",
       "         'NUM': 3326,\n",
       "         'NOUN': 27393,\n",
       "         '.': 11056,\n",
       "         'VERB': 12893,\n",
       "         'X': 6282,\n",
       "         'DET': 8313,\n",
       "         'PRT': 3055,\n",
       "         'PRON': 2581,\n",
       "         'ADV': 3014,\n",
       "         'ADJ': 6092,\n",
       "         'CONJ': 2149})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tag_counts = Counter(all_tags)\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOUN is the commonly used tag in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 27393), ('VERB', 12893), ('.', 11056)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_counts.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Building the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function for calculating Emission Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining function for calculating Transition Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>DET</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRT</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>X</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>0.091172</td>\n",
       "      <td>0.064671</td>\n",
       "      <td>0.221599</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.089454</td>\n",
       "      <td>0.175470</td>\n",
       "      <td>0.052912</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>0.079595</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.091353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRON</td>\n",
       "      <td>0.041069</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.210771</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.481209</td>\n",
       "      <td>0.010074</td>\n",
       "      <td>0.034870</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.072065</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.095312</td>\n",
       "      <td>0.021310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.239988</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.262293</td>\n",
       "      <td>0.042967</td>\n",
       "      <td>0.147592</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.017048</td>\n",
       "      <td>0.043916</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>0.177235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CONJ</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.351792</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.155886</td>\n",
       "      <td>0.117729</td>\n",
       "      <td>0.054444</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.116799</td>\n",
       "      <td>0.041415</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.053979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>VERB</td>\n",
       "      <td>0.034360</td>\n",
       "      <td>0.035290</td>\n",
       "      <td>0.110913</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.169860</td>\n",
       "      <td>0.135190</td>\n",
       "      <td>0.081362</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>0.064997</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.217327</td>\n",
       "      <td>0.091212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DET</td>\n",
       "      <td>0.017082</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.638037</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.039456</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.206664</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.009142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADV</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.342402</td>\n",
       "      <td>0.069675</td>\n",
       "      <td>0.078301</td>\n",
       "      <td>0.013603</td>\n",
       "      <td>0.131387</td>\n",
       "      <td>0.030856</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.119443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRT</td>\n",
       "      <td>0.041899</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.249427</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.401637</td>\n",
       "      <td>0.100164</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.084452</td>\n",
       "      <td>0.054992</td>\n",
       "      <td>0.013093</td>\n",
       "      <td>0.020949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.064183</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.699934</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.065988</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.077479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NUM</td>\n",
       "      <td>0.116055</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.356284</td>\n",
       "      <td>0.012628</td>\n",
       "      <td>0.017138</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.033073</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.210162</td>\n",
       "      <td>0.035478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.055874</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.206145</td>\n",
       "      <td>0.054441</td>\n",
       "      <td>0.025788</td>\n",
       "      <td>0.184655</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.074499</td>\n",
       "      <td>0.146132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADP</td>\n",
       "      <td>0.039851</td>\n",
       "      <td>0.068514</td>\n",
       "      <td>0.322643</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.324241</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.106766</td>\n",
       "      <td>0.061375</td>\n",
       "      <td>0.034523</td>\n",
       "      <td>0.017475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .      PRON      NOUN      CONJ      VERB       DET       ADV  \\\n",
       ".     0.091172  0.064671  0.221599  0.058520  0.089454  0.175470  0.052912   \n",
       "PRON  0.041069  0.008136  0.210771  0.004649  0.481209  0.010074  0.034870   \n",
       "NOUN  0.239988  0.004855  0.262293  0.042967  0.147592  0.013434  0.017048   \n",
       "CONJ  0.035831  0.058167  0.351792  0.000465  0.155886  0.117729  0.054444   \n",
       "VERB  0.034360  0.035290  0.110913  0.005352  0.169860  0.135190  0.081362   \n",
       "DET   0.017082  0.003007  0.638037  0.000361  0.039456  0.005052  0.012751   \n",
       "ADV   0.135700  0.015594  0.032183  0.007299  0.342402  0.069675  0.078301   \n",
       "PRT   0.041899  0.018985  0.249427  0.002291  0.401637  0.100164  0.010147   \n",
       "ADJ   0.064183  0.000657  0.699934  0.016579  0.012311  0.004760  0.004924   \n",
       "NUM   0.116055  0.001203  0.356284  0.012628  0.017138  0.003307  0.003307   \n",
       "X     0.162050  0.055874  0.061764  0.009551  0.206145  0.054441  0.025788   \n",
       "ADP   0.039851  0.068514  0.322643  0.000852  0.008524  0.324241  0.013852   \n",
       "\n",
       "           PRT       ADJ       NUM         X       ADP  \n",
       ".     0.002442  0.045134  0.079595  0.027587  0.091353  \n",
       "PRON  0.013173  0.072065  0.007361  0.095312  0.021310  \n",
       "NOUN  0.043916  0.012047  0.009455  0.029168  0.177235  \n",
       "CONJ  0.005119  0.116799  0.041415  0.008376  0.053979  \n",
       "VERB  0.031568  0.064997  0.022570  0.217327  0.091212  \n",
       "DET   0.000241  0.206664  0.022254  0.045952  0.009142  \n",
       "ADV   0.013603  0.131387  0.030856  0.023557  0.119443  \n",
       "PRT   0.001964  0.084452  0.054992  0.013093  0.020949  \n",
       "ADJ   0.011162  0.065988  0.021011  0.021011  0.077479  \n",
       "NUM   0.024955  0.033073  0.186410  0.210162  0.035478  \n",
       "X     0.184655  0.016237  0.002865  0.074499  0.146132  \n",
       "ADP   0.001385  0.106766  0.061375  0.034523  0.017475  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Vanilla Viterbi Function\n",
    "The above defined functions for calculating transitional and emmision probablities will be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Building Modified Viterbi Function version 1\n",
    "\n",
    "The Vanilla Viterbi function does not perform well in the case of unknown words.\n",
    "The unkown words will have 0 emission probability, so we discard the emission probability **in case of unknown words and consider only transitional probality to calculate the max state probablity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        \n",
    "        # if word is not present in vocabulary\n",
    "        if word in vocabulary:\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p    \n",
    "                p.append(state_probability)\n",
    "        else:\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "                # only transition probablity is considered in case of unknown word\n",
    "                p.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Building Modified Viterbi Function version 2\n",
    "\n",
    "As Vanilla Viterbi function does not perform well in the case of unknown words, we can tag unknown words using rule based taggers. We will be using a 3 layer combined tagger for tagging unkown words.\n",
    "\n",
    "**Top Layer - Bigram Tagger with backoff as Unigram Tagger**\n",
    "\n",
    "**Middle Layer - Unigram tagger with backoff as Regular Expression Tagger**\n",
    "\n",
    "**Last Layer - Regex Tagger**\n",
    "\n",
    "The unknow word will be first tried for tagging with bigram tagger, failing upon unigram tagger will be used, failing which regex tagger will be used.\n",
    "\n",
    "Also as we know the most commonly used tag is NOUN, for fallback purpose will be using NOUN as the default tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a regular expression based tagger\n",
    "regexp_tagger = nltk.RegexpTagger(\n",
    "     [(r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "      (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "      (r'.*able$', 'ADJ'),                # adjectives\n",
    "      (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "      (r'.*ly$', 'ADV'),                  # adverbs\n",
    "      (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "      (r'.*ing$', 'VERB'),                # gerunds\n",
    "      (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "      (r'.*', 'NOUN')                     # nouns (default)\n",
    "])\n",
    "\n",
    "# creating a unigram tagger with backoff as regular expression tagger\n",
    "u_gram_tag=nltk.UnigramTagger(train_set,backoff=regexp_tagger)\n",
    "\n",
    "# creating a bigram tagger with backoff as unigram tagger\n",
    "b_gram_tag=nltk.BigramTagger(train_set,backoff=u_gram_tag)\n",
    "\n",
    "\n",
    "# Viterbi Heuristic\n",
    "def Viterbi3(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        \n",
    "        # if word is not present in vocabulary\n",
    "        if word in vocabulary:\n",
    "            #initialise list of probability column for a given observation\n",
    "            p = [] \n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p    \n",
    "                p.append(state_probability)\n",
    "\n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)]\n",
    "            state.append(state_max)\n",
    "        else:\n",
    "            # using rule based taggers for unknown words\n",
    "            _tagger = b_gram_tag.tag([word])\n",
    "            state_max = _tagger[0][1]\n",
    "            state.append(state_max)\n",
    "        \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating all the 3 Viterbi Taggers\n",
    "\n",
    "### Creating test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# # choose random 5 sents\n",
    "# rndom = [random.randint(1,len(test_set)) for x in range(50)]\n",
    "\n",
    "# # list of sents\n",
    "# test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "# print(test_run_base)\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "# print(test_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Vanilla Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  804.8175868988037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9102589059762507"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "# print(tagged_seq)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Modified Viterbi version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  731.3956158161163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.941989488028032"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "# print(tagged_seq)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Modified Viterbi version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  757.7581079006195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9571734475374732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi3(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "# print(tagged_seq)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Comparing the accuracy of all the 3 taggers\n",
    "\n",
    "Accuracy of Vanilla Viterbi = **91.02%**\n",
    "\n",
    "Accuracy of Modified Viterbi Version 1 = **94.19%**\n",
    "\n",
    "Accuracy of Modified Viterbi Version 2 = **95.71%**\n",
    "\n",
    "So, it clear that Accuracy of Viterbi in tandem with Rule based taggers seems to be performing better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Identifying the cases which were incorrectly tagged by original POS tagger and got corrected by modified Viterbi functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:\n",
    "\n",
    "<font color = blue>'Android'</font> was tagged as '.', then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'Google'</font> was tagged as '.', 'DET' and then corrected to 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', '.'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', '.'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'Android is a mobile operating system developed by Google.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq = Viterbi1(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi2(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi3(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2:\n",
    "\n",
    "<font color = blue>'NASA'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'invited'</font> was tagged as '.','NOUN' and then corrected to 'VERB'\n",
    "\n",
    "<font color = blue>'ICESAT-2'</font> was tagged as '.','DET' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'Satellite'</font> was tagged as '.' and then corrected to 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NASA', '.'), ('invited', '.'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', '.'), ('Satellite', '.'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq = Viterbi1(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi2(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi3(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3:\n",
    "\n",
    "<font color = blue>'Android'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'worldwide'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'smartphones'</font> was tagged as '.','DET' and then corrected as 'NOUN'\n",
    "\n",
    "<font color = blue>'2011'</font> was tagged as '.','DET' and then corrected to 'NUM'\n",
    "\n",
    "<font color = blue>'2013'</font> was tagged as '.','DET' and then corrected to 'NUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', '.'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', '.'), ('worldwide', '.'), ('on', 'ADP'), ('smartphones', '.'), ('since', 'ADP'), ('2011', '.'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', '.'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq = Viterbi1(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi2(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi3(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4:\n",
    "\n",
    "<font color = blue>'2018'</font> was tagged as '.','NOUN' and then corrected to 'NUM'\n",
    "\n",
    "<font color = blue>'FIFA'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'Cup'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'21st'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'tournament'</font> was tagged as '.' and then corrected to 'NOUN'\n",
    "\n",
    "<font color = blue>'contested'</font> was tagged as '.', 'NOUN' and then corrected to 'VERB'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('2018', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), ('is', 'VERB'), ('the', 'DET'), ('21st', '.'), ('FIFA', '.'), ('World', 'NOUN'), ('Cup', '.'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', '.'), ('contested', '.'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sentence_test = 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.'\n",
    "words = word_tokenize(sentence_test)\n",
    "tagged_seq = Viterbi1(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi2(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_seq = Viterbi3(words)\n",
    "print(tagged_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
